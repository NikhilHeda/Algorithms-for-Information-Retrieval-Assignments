{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import nltk.data\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import string\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DESCRIPTION ='''\n",
    "Dataset Description:\n",
    "    .I -> ID\n",
    "    .T -> Title\n",
    "    .A -> Author\n",
    "    .B -> Date\n",
    "    .W -> Actual Text\n",
    "'''\n",
    "\n",
    "FILEPATH = 'Dataset/cran.all.1400'\n",
    "\n",
    "N = 1400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to parse content of Cranfield Dataset\n",
    "Uses Regex for parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(filename):\n",
    "    '''\n",
    "    Input: Filename\n",
    "    Output: List of dictionaries\n",
    "        [ {\n",
    "            'ID':\n",
    "            'Title':\n",
    "            'Author':\n",
    "            'Date':\n",
    "            'Content':\n",
    "        }, ...]\n",
    "    '''\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        contents = f.read()\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r\"\"\"\\.I(?P<ID>.*?)\\.T(?P<Title>.*?)\\.A(?P<Author>.*?)\\.B(?P<Date>.*?)\\.W(?P<Content>.*?(?=\\.I))\"\"\",\n",
    "        re.DOTALL\n",
    "    ) \n",
    "    \n",
    "    parsed_content = [\n",
    "        match.groupdict()\n",
    "        for match in re.finditer(pattern, contents + '.I')\n",
    "    ]\n",
    "    \n",
    "    return parsed_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "- Tokenization\n",
    "- Stop-Word Removal\n",
    "- Stemming and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PreProcessor:\n",
    "    def __init__(self, language):\n",
    "        self.stop_words = set(stopwords.words(language))\n",
    "        self.punctuations = set(string.punctuation)\n",
    "        self.stemmer = PorterStemmer()\n",
    "\n",
    "    def get_tokens(self, data):\n",
    "        '''\n",
    "        Input : Raw text data\n",
    "        Output : List of tokens\n",
    "        '''\n",
    "        return word_tokenize(data)\n",
    "    \n",
    "    def stopword_removal(self, data):\n",
    "        '''\n",
    "        Input : List of tokens\n",
    "        Output : List of tokens without stopwords\n",
    "        '''\n",
    "        return [word for word in data if word not in self.stop_words]\n",
    "\n",
    "    def normalize(self, word):\n",
    "        '''\n",
    "        Input : Word\n",
    "        Ouput : Case formatted and stemmed word\n",
    "        '''\n",
    "        word = str.lower(word)\n",
    "        word = ''.join([letter for letter in word if letter not in self.punctuations ])\n",
    "        word = self.stemmer.stem(word)\n",
    "        return word\n",
    "    \n",
    "    def validate(self, data):\n",
    "        '''\n",
    "        Input : List of words\n",
    "        Ouput : List of words without null words\n",
    "        '''\n",
    "        return list(filter(lambda word: word != '', data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to preprocess documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_documents(parsed_data, begin, end, preprocessor=PreProcessor('english')):\n",
    "    '''\n",
    "    Input : Parsed Data, start and end indices to preprocess data and PreProcessor Object\n",
    "    Output : List of documents which are preprocessed \n",
    "    '''\n",
    "    for i in range(begin, end):\n",
    "        for key in parsed_data[i]:\n",
    "            data = parsed_data[i][key]\n",
    "            data = preprocessor.get_tokens(data)\n",
    "            if key == 'ID':\n",
    "                data = int(data[0])\n",
    "            if key == 'Content':\n",
    "                data = preprocessor.stopword_removal(data)\n",
    "                data = [preprocessor.normalize(word) for word in data]\n",
    "                data = preprocessor.validate(data)\n",
    "            parsed_data[i][key] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Space Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_index(data):\n",
    "    '''\n",
    "    Builds Posting list index structure for retrieval.\n",
    "    '''\n",
    "    index = defaultdict(dict)\n",
    "    \n",
    "    # Calculating Term Frequncy and Building Inverted Index\n",
    "    for document in data:\n",
    "        content = document['Content'] + document['Title']\n",
    "        for term in set(content):\n",
    "            \n",
    "            if term not in index:\n",
    "                index[term]['Posting List'] = []\n",
    "                \n",
    "            index[term]['Posting List'].append({\n",
    "                'ID': document['ID'],\n",
    "                'Term Frequency': content.count(term)\n",
    "            })\n",
    "    \n",
    "    # Calculating Document Frequency\n",
    "    for term in index:\n",
    "        index[term]['Document Frequency'] = len(index[term]['Posting List'])\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weight(tf, df):\n",
    "    '''\n",
    "    Calculates tf-idf weights\n",
    "    '''\n",
    "    if tf == 0 or df == 0:\n",
    "        return 0\n",
    "    return (1 + math.log(tf, 10)) * math.log(N/df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_term_doc_matrix(vocabulary, index):\n",
    "    '''\n",
    "    Builds term-document matrix to vectorize documents.\n",
    "    '''\n",
    "    term_doc_mat = np.zeros((N, len(index)))\n",
    "    \n",
    "    for col, term in enumerate(vocabulary):\n",
    "        for document in index[term]['Posting List']:\n",
    "            term_doc_mat[document['ID'] - 1, col] = get_weight(\n",
    "                tf=document['Term Frequency'],\n",
    "                df=index[term]['Document Frequency']\n",
    "            )\n",
    "\n",
    "    return term_doc_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_query_vector(vocabulary, index, query, preprocessor=PreProcessor('english')):\n",
    "    '''\n",
    "    Preprocesses query and builds a query vector.\n",
    "    '''\n",
    "    # Preprocess Queries\n",
    "    processed_query = preprocessor.get_tokens(query)\n",
    "    #processed_query = preprocessor.stopword_removal(processed_query)\n",
    "    processed_query = [preprocessor.normalize(term) for term in processed_query]\n",
    "    \n",
    "    query_vector = np.zeros((len(vocabulary), 1))\n",
    "    \n",
    "    for row, term in enumerate(vocabulary):\n",
    "        query_vector[row] = get_weight(tf=processed_query.count(term), df=index[term]['Document Frequency'])\n",
    "\n",
    "    return query_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parsed_data = parse_file(FILEPATH)\n",
    "preprocess_documents(parsed_data, 0, len(parsed_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building Index\n",
    "index = build_index(parsed_data)\n",
    "vocabulary = list(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "queries = []\n",
    "queries.append('experimental results on hypersonic viscous interaction')\n",
    "queries.append('properties of impact pressure probes in free molecule flow')\n",
    "queries.append('manufacturing and maintainance of ideally sharp leading edges and noses is practically impossible')\n",
    "queries.append('why does the compressibility transformation fail to correlate the high speed data for helium and air')\n",
    "queries.append('can increasing the edge loading of a plate beyond the critical value for buckling change the buckling mode .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query : experimental results on hypersonic viscous interaction\n",
      "\t  305 - hypersonic strong viscous interaction on a flat plate with surface mass transfer .\n",
      "\t  570 - on the boundary layer equations in hypersonic flow and their approximate solutions .\n",
      "\t  540 - use of local similarity concepts in hypersonic viscous interaction problems .\n",
      "\t  573 - viscous hypersonic similitude .                   \n",
      "\t 1253 - hypersonic viscous flow near the stagnation point in the presence of magnetic field .\n",
      "\t  308 - on the hypersonic viscous flow past a flat plate with suction or injection .\n",
      "\t  310 - hypersonic viscous flow over a flat plate .       \n",
      "\t  323 - vorticity interaction at an axisymmetric stagnation point in a viscous incompressible fluid .\n",
      "\t 1299 - hypersonic viscous shock layer .                  \n",
      "\t  192 - on the hypersonic viscous flow past slender bodies of revolution .\n",
      "Query : properties of impact pressure probes in free molecule flow\n",
      "\t  183 - properties of impact pressure probes in free molecule flow .\n",
      "\t  906 - review of the pitot tube .                        \n",
      "\t   10 - the theory of the impact tube at low pressure .   \n",
      "\t 1257 - an optical boundary-layer probe .                 \n",
      "\t 1151 - experiments on supersonic blunt-body flows .      \n",
      "\t 1391 - shock wave and flow field development in hypersonic re-entry .\n",
      "\t  355 - the injection of air into the dissociated hypersonic laminar boundary layer .\n",
      "\t  552 - chemical kinetics of high temperature air .       \n",
      "\t  356 - on optimum nose curves for missiles in the super-aerodynamic regime .\n",
      "\t   35 - stagnation point of a blunt body in hypersonic flow .\n",
      "Query : manufacturing and maintainance of ideally sharp leading edges and noses is practically impossible\n",
      "\t  211 - effect of slight blunting of leading edge of an immersed body on the flow around it at hypersonic speed .\n",
      "\t 1387 - the buckling of a square panel under shear , when one pair of opposite edges is clamped and the other pair is simply supported .\n",
      "\t  922 - supersonic flow past slender bodies of revolution , slope of whose median section is discontinuous .\n",
      "\t  900 - some measurements in the vortex flow generated by a sharp leading edge having 65 sweep .\n",
      "\t  167 - linearized flow of a dissociating gas .           \n",
      "\t  212 - theory and tunnel tests of rotor blade for supersonic turbines .\n",
      "\t 1196 - growth of the turbulent wake behind a supersonic sphere .\n",
      "\t  332 - similitude of hypersonic real-gas flows over slender bodies with blunted noses .\n",
      "\t  918 - on the low aspect ratio oscillating rectangular wing in supersonic flow .\n",
      "\t  465 - slender delta wings with sharp edges at zero lift .\n",
      "Query : why does the compressibility transformation fail to correlate the high speed data for helium and air\n",
      "\t  502 - on squire 's test of the compressibility transformation .\n",
      "\t   68 - some aspects of air-helium simulation and hypersonic approximations .\n",
      "\t  421 - analytic study of induced pressure on long bodies of revolution with varying nose bluntness at hypersonic speeds .\n",
      "\t  343 - transpiration cooling experiments in a turbulent boundary layer at m=3 .\n",
      "\t  460 - correlated incompressible and compressible boundary layers .\n",
      "\t  686 - flutter tests of some simple models at a mach number of 7 . 2 in helium flow .\n",
      "\t  413 - turbulent skin friction at high mach numbers and reynolds numbers in air and helium . nasa r82 , 1960 .\n",
      "\t 1007 - free-flight measurements of the static and dynamic .\n",
      "\t 1026 - note on creep buckling of columns .               \n",
      "\t 1176 - bending tests of ring-stiffened circular cylinders .\n",
      "Query : can increasing the edge loading of a plate beyond the critical value for buckling change the buckling mode .\n",
      "\t  609 - on three dimensional bodies of delta planform which can support plane attached shock waves .\n",
      "\t  862 - the phenomenon of change in buckle pattern in elastic structures .\n",
      "\t   15 - on two-dimensional panel flutter .                \n",
      "\t  642 - the buckling strength of a uniform circular cylinder loaded in axial compression .\n",
      "\t 1015 - principles of creep buckling weight-strength analysis .\n",
      "\t  245 - the ground effect on the jet flap in two dimensions .\n",
      "\t 1398 - stability of rectangular plates under shear and bending forces .\n",
      "\t 1023 - note on creep buckling of columns .               \n",
      "\t 1177 - effects of rapid heating on strength of airframe components .\n",
      "\t  843 - a simplified method of elastic stability analysis for thin cylindrical shells .\n"
     ]
    }
   ],
   "source": [
    "result = build_term_doc_matrix(vocabulary, index)\n",
    "result_normalized = preprocessing.normalize(result, norm='l2')\n",
    "\n",
    "for query in queries:\n",
    "    print(\"Query :\", query)\n",
    "    query_vector = get_query_vector(vocabulary, index, query)\n",
    "    result = list(enumerate(np.matmul(result_normalized, query_vector), start=1))\n",
    "    \n",
    "    result.sort(key=lambda x : x[1], reverse=True)\n",
    "\n",
    "    for i, score in result[:10]:\n",
    "        print(\"\\t{0:5} - {1:50}\".format(i, ' '.join(parsed_data[i - 1]['Title'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
